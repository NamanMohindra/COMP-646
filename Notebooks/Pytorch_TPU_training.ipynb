{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX1hxqUQn47M"
      },
      "source": [
        "## PyTorch/XLA ResNet18/CIFAR10 (GPU or TPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLQPoJ6Fn8wF"
      },
      "source": [
        "### [RUNME] Install Colab compatible PyTorch/XLA wheels and dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OApBOAe1fpH_",
        "outputId": "16570172-3806-419f-8d80-00d96df9f275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-xla==1.11\n",
            "  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl (152.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 152.9 MB 28 kB/s \n",
            "\u001b[?25hCollecting cloud-tpu-client==0.10\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0) (4.2.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.31.5)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.35.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (21.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2022.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.56.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Installing collected packages: google-api-python-client, torch-xla, cloud-tpu-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 1.12.11\n",
            "    Uninstalling google-api-python-client-1.12.11:\n",
            "      Successfully uninstalled google-api-python-client-1.12.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "earthengine-api 0.1.306 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0 torch-xla-1.11\n"
          ]
        }
      ],
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfSCdVlA8jFg"
      },
      "source": [
        "### If you're using GPU with this colab notebook, run the below commented code to install GPU compatible PyTorch wheel and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "multiprocessing.cpu_count()"
      ],
      "metadata": {
        "id": "MJlmZkiCultt",
        "outputId": "24a70208-5e83-4ad1-c0b2-a86a1c767480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1Vfg-rH8bF4"
      },
      "outputs": [],
      "source": [
        "#!pip install cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/cuda/112/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl --force-reinstall "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPrij_iPfqTV"
      },
      "source": [
        "### Only run the below commented cell if you would like a nightly release"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJZrkoejQhxK"
      },
      "outputs": [],
      "source": [
        "# VERSION = \"1.11\"  #@param [\"1.11\", \"nightly\", \"20220315\"]  # or YYYYMMDD format\n",
        "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "# !python pytorch-xla-env-setup.py --version $VERSION\n",
        "# import os \n",
        "# os.environ['LD_LIBRARY_PATH']='/usr/local/lib'\n",
        "# !echo $LD_LIBRARY_PATH\n",
        "\n",
        "# !sudo ln -s /usr/local/lib/libmkl_intel_lp64.so /usr/local/lib/libmkl_intel_lp64.so.1\n",
        "# !sudo ln -s /usr/local/lib/libmkl_intel_thread.so /usr/local/lib/libmkl_intel_thread.so.1\n",
        "# !sudo ln -s /usr/local/lib/libmkl_core.so /usr/local/lib/libmkl_core.so.1\n",
        "\n",
        "# !ldconfig\n",
        "# !ldd /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiFzLg5gy7l6"
      },
      "outputs": [],
      "source": [
        "# PyTorch/XLA GPU Setup (only if GPU runtime)\n",
        "import os\n",
        "# if os.environ.get('COLAB_GPU', '0') == '1':\n",
        "#   os.environ['GPU_NUM_DEVICES'] = '1'\n",
        "#   os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the clevr dataset takes about 5-7 min\n",
        "!wget https://dl.fbaipublicfiles.com/clevr/CLEVR_v1.0.zip\n",
        "# unzip the file takes about 3 min\n",
        "!unzip -q CLEVR_v1.0.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArZsrE53GZy9",
        "outputId": "ebaec7fa-a3c0-44c4-a4b7-7fe8dfa88bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-27 09:05:55--  https://dl.fbaipublicfiles.com/clevr/CLEVR_v1.0.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19021600724 (18G) [application/zip]\n",
            "Saving to: ‘CLEVR_v1.0.zip’\n",
            "\n",
            "CLEVR_v1.0.zip      100%[===================>]  17.71G  54.8MB/s    in 5m 29s  \n",
            "\n",
            "2022-04-27 09:11:25 (55.1 MB/s) - ‘CLEVR_v1.0.zip’ saved [19021600724/19021600724]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install the transformer library\n",
        "!pip -q install transformers"
      ],
      "metadata": {
        "id": "rmW6kM3_HoWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212a80f6-6252-45d6-e850-ccc4337ba413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.0 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 44.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 72.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 70.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets explore the dataset\n",
        "import json\n",
        "#training_questions = json.load(open(\"CLEVR_v1.0/questions/CLEVR_train_questions.json\"))\n",
        "#valid_questions = json.load(open(\"CLEVR_v1.0/questions/CLEVR_val_questions.json\"))"
      ],
      "metadata": {
        "id": "GOOcxJYtI64_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "klsddoUaI62r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "questions - contains all the questions,\n",
        "image_index - tells us for which image the question is for\n",
        "question_index - is a unique id for the question\n",
        "program - idk\n",
        "image_filename - gives the image file name for which this question is asked\n",
        "question_family_index - Question family (read the CLEVR paper for details)\n",
        "answer - this is the answer to the question \n",
        "        There is something fishy with the answers only 28 unique answers\n",
        "        in all the training data\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "from collections import defaultdict\n",
        "temp_dictionary = defaultdict(int)\n",
        "# temp set should contain all the different answers that are there in the dataset\n",
        "temp_set = set()\n",
        "\n",
        "#for index,i in enumerate(training_questions[\"questions\"]):\n",
        "    # temp_dictionary[i[\"answer\"]] += 1\n",
        "    #temp_set.add(i[\"answer\"])\n",
        "    # if index < 5:\n",
        "    #     #print(i.keys())\n",
        "    #     print(i[\"image_filename\"])\n",
        "    #     print(i[\"answer\"])\n",
        "    # else:\n",
        "    #     break\n",
        "\n",
        "\n",
        "#print(len(temp_set))\n",
        "\n",
        "# for index,i in enumerate(valid_questions[\"questions\"]):\n",
        "#     # temp_dictionary[i[\"answer\"]] += 1\n",
        "#     # temp_set.add(i[\"answer\"])\n",
        "#     if index < 5:\n",
        "#         #print(i.keys())\n",
        "#         print(i[\"question\"])\n",
        "#         print(i[\"answer\"])\n",
        "#     else:\n",
        "#         break\n",
        "\n",
        "\n",
        "# print(len(temp_set))"
      ],
      "metadata": {
        "id": "c6UMFqt0I6z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.utils.utils as xu\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "import torch, os, json\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertTokenizer\n",
        "from PIL import Image\n",
        "import torchvision.models as models\n",
        "\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItknMcdFgPvb",
        "outputId": "d1a269b1-9cbb-4a46-c299-6a8705a70809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.11...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.11...\n",
            "WARNING:root:TPU has started up successfully with version pytorch-1.11\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe397c533f0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YgWO5Acf5k8o",
        "outputId": "7f9a1360-e450-4070-9212-88627c77f137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.11.0+cu113'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Defining the dataloader \n",
        "class CLEVER(torch.utils.data.Dataset):\n",
        "    def __init__(self,categories = None,folder = 'CLEVR_v1.0/', split = \"train\",transformation = None):\n",
        "        self.json_dir = os.path.join(folder,'questions',f\"CLEVR_{split}_questions.json\")\n",
        "        self.image_dir = os.path.join(folder,'images',split)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.categories = categories\n",
        "        self.data = []\n",
        "        self.cat2id = {i:index for index,i in enumerate(categories)}\n",
        "        self.id2cat = {index:i for index,i in enumerate(categories)}\n",
        "        self.transformation = transformation\n",
        "        json_file = json.load(open(self.json_dir))\n",
        "        \n",
        "        for index,i in enumerate(json_file[\"questions\"]):\n",
        "            text = i[\"question\"]\n",
        "            answer = self.cat2id[i[\"answer\"]]\n",
        "            self.data.append((i[\"image_index\"],i[\"image_filename\"],text,answer))\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        image_path = os.path.join(self.image_dir,self.data[index][1])\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transformation != None:\n",
        "            image = self.transformation(image)\n",
        "        text = self.data[index][2]\n",
        "        encoded_text = self.tokenizer.encode_plus(\n",
        "                text, add_special_tokens = True, truncation = True, \n",
        "                max_length = 256, padding = 'max_length',\n",
        "                return_attention_mask = True,\n",
        "                return_tensors = 'pt')\n",
        "        text = encoded_text['input_ids'][0]\n",
        "        attention_mask = encoded_text['attention_mask'][0]\n",
        "        answer = self.data[index][3]\n",
        "        return image,text,attention_mask,answer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n"
      ],
      "metadata": {
        "id": "oDCWSnHCUlwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#categories = list(sorted(list(temp_set)))\n",
        "categories = ['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9', 'blue', 'brown', 'cube', 'cyan', 'cylinder', 'gray', 'green', 'large', 'metal', 'no', 'purple', 'red', 'rubber', 'small', 'sphere', 'yellow', 'yes']\n",
        "print(categories)\n",
        "\n",
        "# norm = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "# transform_train = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     norm,\n",
        "# ])\n",
        "\n",
        "#train_data = CLEVER(categories = categories,split = 'train',transformation = transform_train)\n",
        "# valid_data = CLEVER(categories = categories,split = 'val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ckKGXbkw_Jh",
        "outputId": "36020cef-fc1f-4172-f278-a056fcd3d618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9', 'blue', 'brown', 'cube', 'cyan', 'cylinder', 'gray', 'green', 'large', 'metal', 'no', 'purple', 'red', 'rubber', 'small', 'sphere', 'yellow', 'yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#         train_data,\n",
        "#         batch_size=FLAGS['batch_size'],\n",
        "#         num_workers=FLAGS['num_workers'],\n",
        "#         drop_last=True)\n",
        "\n",
        "# model = custom_model(categories)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=5e-4)\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# def train_loop_fn(loader):\n",
        "#     model.train()\n",
        "    \n",
        "#     for x, (img,text,mask,label) in enumerate(loader):\n",
        "#         optimizer.zero_grad()\n",
        "#         output = model(img,text,mask)\n",
        "#         loss = loss_fn(output, label)\n",
        "#         print(loss)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "# # Train and eval loops\n",
        "# accuracy = 0.0\n",
        "# data, pred, target = None, None, None\n",
        "# for epoch in range(1, FLAGS['num_epochs'] + 1):\n",
        "#     print(epoch)\n",
        "#     train_loop_fn(train_loader)\n"
      ],
      "metadata": {
        "id": "23wcVqEii-Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertConfig\n",
        "\n",
        "# # Loading BERT...\n",
        "# num_categories = len(categories)\n",
        "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', \n",
        "#     num_labels = num_categories,  output_attentions = False, \n",
        "#     output_hidden_states = False)"
      ],
      "metadata": {
        "id": "VOIlmFnvxwaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class custom_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(custom_model, self).__init__()\n",
        "\n",
        "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', \n",
        "        num_labels = 28,  output_attentions = False, \n",
        "        output_hidden_states = False)\n",
        "\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.cnn = models.efficientnet_b0(pretrained = True)\n",
        "        for param in self.cnn.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(1028,500)\n",
        "        self.linear2 = torch.nn.Linear(500,28)\n",
        "\n",
        "    def forward(self,image_data,text_data,text_masks):\n",
        "        x1 = self.cnn(image_data)\n",
        "        x2 = self.bert(text_data,text_masks)\n",
        "        x = torch.cat((x1,x2.logits),dim = 1)\n",
        "        x = self.linear1(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GpK4UnYX6wBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EOT3Wr5eFfju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SERIAL_EXEC = xmp.MpSerialExecutor()\n",
        "# Only instantiate model weights once in memory.\n",
        "WRAPPED_MODEL = xmp.MpModelWrapper(custom_model())\n",
        "\n",
        "def train_custom_model():\n",
        "    torch.manual_seed(1)\n",
        "\n",
        "    def get_dataset():\n",
        "        norm = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            norm,\n",
        "        ])\n",
        "        transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            norm,\n",
        "        ])\n",
        "        train_dataset = CLEVER(categories = categories,split = 'train',transformation = transform_train)\n",
        "        test_dataset = CLEVER(categories = categories,split = 'val',transformation = transform_test)\n",
        "        \n",
        "        return train_dataset, test_dataset\n",
        "    \n",
        "    # Using the serial executor avoids multiple processes\n",
        "    # to download the same data.\n",
        "    train_dataset, test_dataset = SERIAL_EXEC.run(get_dataset)\n",
        "\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "            train_dataset,\n",
        "            num_replicas=xm.xrt_world_size(),\n",
        "            rank=xm.get_ordinal(),\n",
        "            shuffle=True)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=FLAGS['batch_size'],\n",
        "            sampler=train_sampler,\n",
        "            num_workers=FLAGS['num_workers'],\n",
        "            drop_last=True)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=FLAGS['batch_size'],\n",
        "            shuffle=False,\n",
        "            num_workers=FLAGS['num_workers'],\n",
        "            drop_last=True)\n",
        "\n",
        "    # Scale learning rate to num cores\n",
        "    learning_rate = FLAGS['learning_rate'] * xm.xrt_world_size()\n",
        "\n",
        "    # Get loss function, optimizer, and model\n",
        "    device = xm.xla_device()\n",
        "    model = WRAPPED_MODEL.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay=5e-4)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def train_loop_fn(loader):\n",
        "        tracker = xm.RateTracker()\n",
        "        model.train()\n",
        "        for x, (img,text,mask,label) in enumerate(loader):\n",
        "            optimizer.zero_grad()\n",
        "            output = model(img,text,mask)\n",
        "            loss = loss_fn(output, label)\n",
        "            #print(loss)\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(optimizer)\n",
        "            tracker.add(FLAGS['batch_size'])\n",
        "            if x % FLAGS['log_steps'] == 0:\n",
        "                print('[xla:{}]({}) Loss={:.5f} Rate={:.2f} GlobalRate={:.2f} Time={}'.format(\n",
        "                    xm.get_ordinal(), x, loss.item(), tracker.rate(),\n",
        "                    tracker.global_rate(), time.asctime()), flush=True)\n",
        "\n",
        "    def test_loop_fn(loader):\n",
        "        total_samples = 0\n",
        "        correct = 0\n",
        "        model.eval()\n",
        "        data, pred, target = None, None, None\n",
        "        for x, (img,text,mask,label) in enumerate(loader):\n",
        "            output = model(img,text,mask)\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            #print(pred)\n",
        "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
        "            total_samples += data.size()[0]\n",
        "\n",
        "            accuracy = 100.0 * correct / total_samples\n",
        "            print('[xla:{}] Accuracy={:.2f}%'.format(\n",
        "                xm.get_ordinal(), accuracy), flush=True)\n",
        "        return accuracy, data, pred, target\n",
        "\n",
        "    # Train and eval loops\n",
        "    accuracy = 0.0\n",
        "    data, pred, target = None, None, None\n",
        "    for epoch in range(1, FLAGS['num_epochs'] + 1):\n",
        "        para_loader = pl.ParallelLoader(train_loader, [device])\n",
        "        train_loop_fn(para_loader.per_device_loader(device))\n",
        "        xm.master_print(\"Finished training epoch {}\".format(epoch))\n",
        "\n",
        "        #para_loader = pl.ParallelLoader(test_loader, [device])\n",
        "        #accuracy, data, pred, target  = test_loop_fn(para_loader.per_device_loader(device))\n",
        "        if FLAGS['metrics_debug']:\n",
        "            xm.master_print(met.metrics_report(), flush=True)\n",
        "\n",
        "    return accuracy, data, pred, target\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL4HfrTq6v_I",
        "outputId": "82c5cf96-dab4-4d81-baec-9ca7d67d8772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ.get('TPU_NAME', None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LGwcV_Vmp8f-",
        "outputId": "4802334e-b95f-4dcf-a2b1-0a78eae7cc5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'grpc://10.37.141.2:8470'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Parameters\n",
        "FLAGS = {}\n",
        "FLAGS['batch_size'] = 128\n",
        "FLAGS['num_workers'] = 8\n",
        "FLAGS['learning_rate'] = 0.001 #0.02\n",
        "FLAGS['momentum'] = 0.9\n",
        "FLAGS['num_epochs'] = 20\n",
        "FLAGS['num_cores'] = 8 # 8 for tpu 1 for gpu\n",
        "FLAGS['log_steps'] = 20\n",
        "FLAGS['metrics_debug'] = False"
      ],
      "metadata": {
        "id": "zTnOAnKgemuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _mp_fn(rank, flags): # Start training processes\n",
        "    global FLAGS\n",
        "    FLAGS = flags\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    accuracy, data, pred, target = train_custom_model()\n",
        "\n",
        "\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n",
        "        start_method='fork')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "dT2GpnLeemrt",
        "outputId": "c440a2c3-3be8-4100-df23-ea4181c3adf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-3c5635bac230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n\u001b[0;32m----> 9\u001b[0;31m         start_method='fork')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    109\u001b[0m         ready = multiprocessing.connection.wait(\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         )\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w6kyV_XWempL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K-hz9UF1emmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trying an alternate way\n"
      ],
      "metadata": {
        "id": "HJV28NiFUtZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "\n",
        "norm = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    norm,\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    norm,\n",
        "])\n",
        "\n",
        "train_dataset = CLEVER(categories = categories,split = 'train',transformation = transform_train)\n",
        "test_dataset = CLEVER(categories = categories,split = 'val',transformation = transform_test)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=FLAGS['batch_size'],\n",
        "        num_workers=FLAGS['num_workers'],\n",
        "        drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=FLAGS['batch_size'],\n",
        "        shuffle=False,\n",
        "        num_workers=FLAGS['num_workers'],\n",
        "        drop_last=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "3iJWKoE50Fy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flags = {\n",
        "    \"num_epochs\":10,\n",
        "    \"batch_size\":32,\n",
        "    \"num_workers\":8,\n",
        "}\n",
        "\n",
        "\n",
        "def _mp_fn(index,flags):\n",
        "    torch.manual_seed(42)\n",
        "    device = xm.xla_device()\n",
        "\n",
        "    norm = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        norm,\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        norm,\n",
        "    ])\n",
        "\n",
        "    if not xm.is_master_ordinal():\n",
        "        xm.rendezvous('download_only_once')\n",
        "    \n",
        "    train_dataset = CLEVER(categories = categories,split = 'train',transformation = transform_train)\n",
        "    test_dataset = CLEVER(categories = categories,split = 'val',transformation = transform_test)\n",
        "\n",
        "    if xm.is_master_ordinal():\n",
        "        xm.rendezvous('download_only_once')\n",
        "    \n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "    train_dataset,\n",
        "    num_replicas=xm.xrt_world_size(),\n",
        "    rank=xm.get_ordinal(),\n",
        "    shuffle=True)\n",
        "\n",
        "    test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "    test_dataset,\n",
        "    num_replicas=xm.xrt_world_size(),\n",
        "    rank=xm.get_ordinal(),\n",
        "    shuffle=False)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=flags['batch_size'],\n",
        "        sampler=train_sampler,\n",
        "        num_workers=flags['num_workers'],\n",
        "        drop_last=True)\n",
        "    \n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "            test_dataset,\n",
        "            sampler=test_sampler,\n",
        "            batch_size=flags['batch_size'],\n",
        "            shuffle=False,\n",
        "            num_workers=flags['num_workers'],\n",
        "            drop_last=True)\n",
        "\n",
        "    model = custom_model().to(device).train()\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(),lr = 0.001)\n",
        "    for epoch in range(flags[\"num_epochs\"]):\n",
        "        para_train_loader = pl.ParallelLoader(train_loader, [device]).per_device_loader(device)\n",
        "        for x, (img,text,mask,label) in enumerate(para_train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output = model(img,text,mask)\n",
        "            loss = loss_fn(output, label)\n",
        "            print(loss)\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(optimizer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    xmp.spawn(_mp_fn,args=(flags,), nprocs = 8, start_method = \"fork\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "VHT9P9_hZAMB",
        "outputId": "ee159f9a-c7b9-4682-9c49-53167fc2f623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ProcessExitedException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9b91c8e63db9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mp_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"fork\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0merror_pid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfailed_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mexit_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                     \u001b[0msignal_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 )\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mProcessExitedException\u001b[0m: process 0 terminated with signal SIGKILL"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Le13iUyYZAKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oF1PsDVmZE9X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Pytorch TPU + CLEVR training",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
